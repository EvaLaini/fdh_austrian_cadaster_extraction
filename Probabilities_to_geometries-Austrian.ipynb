{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import h_minima, watershed, label\n",
    "\n",
    "from dh_segment_torch.inference import InferenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '/dhlabdata4/benali/'\n",
    "MODELS = DATA + 'models/1848/'\n",
    "IMAGES = DATA + 'cadaster_1848_test/splits/'\n",
    "\n",
    "IMG_NAME = 'cannaregio_07-11_crop05'\n",
    "MODEL_EDGES_NAME = 'model_edges2_n02'\n",
    "MODEL_CLASSES_NAME = 'model_classes_inv_n01'\n",
    "\n",
    "IMG_FORMAT = '.tif'\n",
    "#TYPE = 'full' # indicates training with classes and edges\n",
    "TYPE = 'sep' # indicates separate training for classes and edges\n",
    "\n",
    "\n",
    "IMG = IMAGES + IMG_NAME + IMG_FORMAT\n",
    "EDGES = MODELS + MODEL_EDGES_NAME + '.pth'\n",
    "#EDGES = DATA + 'models/1808/' + MODEL_EDGES_NAME + '.pth'\n",
    "CLASSES = MODELS + MODEL_CLASSES_NAME + '.pth'\n",
    "\n",
    "#DEVICE = 'cpu'\n",
    "DEVICE = 'cuda:4'\n",
    "SAVE_GEOJSON = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_edges = InferenceModel.from_params({\n",
    "    \"model\": {\n",
    "        \"encoder\": \"resnet50\",\n",
    "        \"decoder\": {\n",
    "            \"decoder_channels\": [512, 256, 128, 64, 32],\n",
    "            \"max_channels\": 512\n",
    "        }\n",
    "    }, # Copier/coller du fichier config\n",
    "    \"num_classes\": 2, # A inferer depuis le fichier\n",
    "    \"model_state_dict\": EDGES,\n",
    "    \"device\": DEVICE, # utiliser cuda:0 (ou /1/2)\n",
    "    \"patch_size\": (500,500), # a adapter en fonction\n",
    "    \"patches_batch_size\": 8,\n",
    "    \"patches_overlap\": 0.2, # entre 0 et 1\n",
    "    \"multilabel\": False, #\n",
    "})\n",
    "\n",
    "model_classes = InferenceModel.from_params({\n",
    "    \"model\": {\n",
    "        \"encoder\": \"resnet50\",\n",
    "        \"decoder\": {\n",
    "            \"decoder_channels\": [512, 256, 128, 64, 32],\n",
    "            \"max_channels\": 512\n",
    "        }\n",
    "    },\n",
    "    \"num_classes\": 6,\n",
    "    \"model_state_dict\": CLASSES,\n",
    "    \"device\": DEVICE,\n",
    "    \"patch_size\": (500,500),\n",
    "    \"patches_batch_size\": 8,\n",
    "    \"patches_overlap\": 0,\n",
    "    \"multilabel\": False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMG)[:,:,::-1].copy() # lit l'image en RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = torch.from_numpy(img.transpose(2,0,1)/255).float().unsqueeze(0) # transforme en pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_edges = model_edges.predict_patches(img_torch)[0] \n",
    "\n",
    "probs_classes = model_classes.predict_patches(img_torch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(probs_edges.cpu().numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(probs_classes.cpu().numpy()[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countours = probs_edges.cpu().numpy()[1]\n",
    "\n",
    "minimas = label(h_minima(countours, 0.1))\n",
    "\n",
    "watershed_parcels = watershed((255 * countours).astype('int'), minimas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(img, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Cadaster')\n",
    "\n",
    "ax[1].imshow(watershed_parcels, cmap=plt.cm.nipy_spectral)\n",
    "ax[1].set_title('Watershed parcels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2class = dict(enumerate(['background', 'street', 'water', 'church', 'courtyard', 'building']))\n",
    "num_parcels= np.unique(watershed_parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affine import Affine\n",
    "\n",
    "if (IMG_FORMAT == '.tif'):\n",
    "    transform = rasterio.open(IMG).transform\n",
    "else:\n",
    "    geotransform = (0, 1, 0.0, 0, 0, -1)\n",
    "    transform = Affine.from_gdal(*geotransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_parcel2res(parcel_idx, probs_classes=probs_classes, watershed_parcels=watershed_parcels):\n",
    "    mask_parcel = watershed_parcels == parcel_idx\n",
    "    class_idx = np.bincount(probs_classes.cpu()[0:, mask_parcel].argmax(axis=0)).argmax()\n",
    "    contours, hierarchy = cv2.findContours(mask_parcel.astype('uint8').copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    poly1 = (cv2.approxPolyDP(contours[0], 1, closed=True)[:,0,:]).tolist()\n",
    "    poly1.append(poly1[0])\n",
    "    poly1 = [transform*x for x in poly1]\n",
    "    holes = []\n",
    "    for h in contours[1:]:\n",
    "        poly2 = (cv2.approxPolyDP(h, 1, closed=True)[:,0,:]).tolist()\n",
    "        poly2.append(poly2[0])\n",
    "        poly2 = [transform*x for x in poly2]\n",
    "        holes.append(poly2)\n",
    "    poly = geometry.Polygon(poly1, holes=holes)\n",
    "    return poly, idx2class[class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for idx in tqdm(num_parcels):\n",
    "    results.append(num_parcel2res(idx))\n",
    "    \n",
    "all_polys = [x[0] for x in results]\n",
    "all_classes = [x[1] for x in results]\n",
    "\n",
    "all_polys = gpd.GeoSeries(all_polys)\n",
    "all_polys.crs = 'EPSG:3004'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata = all_polys.to_frame('geometry')\n",
    "geodata['class'] = all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#000000', '#FFFF00','#00FFFF','#FF0000','#00FF00','#FF00FF']\n",
    "fig, axes = plt.subplots(ncols=2,figsize = (16,8))\n",
    "ax = axes.ravel()\n",
    "for idx, label in idx2class.items():\n",
    "    geodata.loc[geodata['class'] == label]['geometry'].plot(color=palette[idx], label=label, ax=ax[1])\n",
    "ax[0].imshow(watershed_parcels, cmap=plt.cm.nipy_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_GEOJSON:\n",
    "    if TYPE == 'sep':\n",
    "        geodata.to_file(MODELS + 'geojsons/' + IMG_NAME + MODEL_EDGES_NAME + MODEL_CLASSES_NAME + '.geojson',\n",
    "                        driver='GeoJSON')\n",
    "    elif TYPE == 'full':\n",
    "        geodata.to_file(MODELS + 'geojsons/' + IMG_NAME + MODEL_FULL_NAME + '.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
